/**
 * Stalled Jobì„ ì²˜ë¦¬í•˜ëŠ” ë³„ë„ Worker
 *
 * íœì‹± í† í°ê³¼ AbortControllerë¥¼ ì‚¬ìš©í•˜ì—¬
 * ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ ì—†ì´ ì•ˆì „í•˜ê²Œ stalled jobì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 */
import 'reflect-metadata';
import { Worker, Job, UnrecoverableError } from 'bullmq';
import Redis from 'ioredis';

const redis = new Redis({ host: 'localhost', port: 6379 });
const workerId = `stalled-${Math.random().toString(36).substring(7)}`;

// íœì‹± í† í° TTL (ì´ˆ)
const FENCING_TOKEN_TTL = 3600;

// í™œì„± job ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
interface JobContext {
  abortController: AbortController;
  fencingToken: string;
  lockExtendInterval: ReturnType<typeof setInterval> | null;
  isAborted: boolean;
}

const activeJobs = new Map<string, JobContext>();

console.log(`\nğŸ”§ Stalled Worker started: ${workerId}`);
console.log(`   - lockDuration: 30000ms`);
console.log(`   - stalledInterval: 15000ms`);
console.log(`   - Fencing Token enabled\n`);

/**
 * íœì‹± í† í° íšë“
 */
async function acquireFencingToken(jobId: string): Promise<string> {
  const tokenKey = `fencing:${jobId}`;
  const token = `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;

  const tokenInfo = {
    token,
    workerId,
    createdAt: Date.now(),
  };

  await redis.set(tokenKey, JSON.stringify(tokenInfo), 'EX', FENCING_TOKEN_TTL);

  console.log(`ğŸ” [${workerId}] Acquired fencing token: ${token.substring(0, 8)}...`);
  return token;
}

/**
 * íœì‹± í† í° ê²€ì¦
 */
async function validateFencingToken(jobId: string, token: string): Promise<boolean> {
  const tokenKey = `fencing:${jobId}`;
  const storedData = await redis.get(tokenKey);

  if (!storedData) {
    return false;
  }

  const tokenInfo = JSON.parse(storedData);
  return tokenInfo.token === token;
}

/**
 * ìŠ¤íŠ¸ë¦¼ ë°œí–‰ (ê²€ì¦ ì—†ì´ - í† í° ê²€ì¦ì€ Lock ê°±ì‹  ì‹œì ì— ìˆ˜í–‰)
 */
async function publish(
  jobId: string,
  fencingToken: string,
  data: any
): Promise<void> {
  const streamKey = `research:${jobId}`;

  const enrichedData = {
    ...data,
    fencingToken: fencingToken.substring(0, 8),
  };

  console.log(
    `ğŸ“¤ [${workerId}] Publishing:`,
    JSON.stringify({ status: data.status, step: data.step || 'N/A' })
  );

  await redis.xadd(streamKey, '*', 'data', JSON.stringify(enrichedData));
  await redis.publish(streamKey, JSON.stringify(enrichedData));
}

/**
 * íœì‹± í† í° í•´ì œ
 */
async function releaseFencingToken(jobId: string, token: string): Promise<void> {
  const tokenKey = `fencing:${jobId}`;

  const script = `
    local stored = redis.call('GET', KEYS[1])
    if stored then
      local info = cjson.decode(stored)
      if info.token == ARGV[1] then
        redis.call('DEL', KEYS[1])
        return 1
      end
    end
    return 0
  `;

  await redis.eval(script, 1, tokenKey, token);
}

/**
 * Lock ìë™ ê°±ì‹  + íœì‹± í† í° ê²€ì¦ (10ì´ˆë§ˆë‹¤)
 */
function startLockExtension(
  job: Job,
  jobId: string,
  signal: AbortSignal,
  context: JobContext
): ReturnType<typeof setInterval> {
  const interval = setInterval(async () => {
    if (signal.aborted) {
      clearInterval(interval);
      return;
    }

    try {
      // 1. Lock ì—°ì¥
      await job.extendLock(job.token!, 30000);
      console.log(`ğŸ”„ [${workerId}] Lock extended for: ${jobId}`);

      // 2. íœì‹± í† í° ê²€ì¦
      const isValid = await validateFencingToken(jobId, context.fencingToken);
      if (!isValid) {
        console.log(`ğŸš« [${workerId}] Fencing token invalidated: ${jobId}`);
        abortJob(jobId, 'Fencing token invalidated');
      }
    } catch (error) {
      console.error(`âš ï¸ [${workerId}] Failed to extend lock:`, error);
      abortJob(jobId, 'Failed to extend lock');
    }
  }, 10000);

  return interval;
}

/**
 * Job ì¤‘ë‹¨
 */
function abortJob(jobId: string, reason: string) {
  const context = activeJobs.get(jobId);
  if (context && !context.isAborted) {
    console.log(`ğŸ›‘ [${workerId}] Aborting job: ${jobId} - ${reason}`);
    context.isAborted = true;
    context.abortController.abort();
  }
}

/**
 * Job ì •ë¦¬
 */
function cleanupJob(jobId: string) {
  const context = activeJobs.get(jobId);
  if (context) {
    if (context.lockExtendInterval) {
      clearInterval(context.lockExtendInterval);
    }
    activeJobs.delete(jobId);
    console.log(`ğŸ§¹ [${workerId}] Cleaned up job context: ${jobId}`);
  }
}

/**
 * ì¸í„°ëŸ½íŠ¸ ê°€ëŠ¥í•œ ë”œë ˆì´
 */
function interruptibleDelay(ms: number, signal: AbortSignal): Promise<void> {
  return new Promise((resolve, reject) => {
    const timeout = setTimeout(resolve, ms);

    signal.addEventListener(
      'abort',
      () => {
        clearTimeout(timeout);
        reject(new UnrecoverableError('Delay interrupted by abort'));
      },
      { once: true }
    );
  });
}

// LLM ì„œë²„ URL (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •)
const LLM_SERVER_URL = process.env.LLM_SERVER_URL || '';

/**
 * ì—°êµ¬ ì‘ì—… ìˆ˜í–‰ - LLM ì„œë²„ í˜¸ì¶œ ë˜ëŠ” ì‹œë®¬ë ˆì´ì…˜
 */
async function executeResearch(
  job: Job,
  jobId: string,
  query: string,
  context: JobContext,
  signal: AbortSignal,
  fencingToken: string
): Promise<string> {
  // LLM ì„œë²„ URLì´ ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
  if (!LLM_SERVER_URL) {
    return executeResearchSimulation(job, jobId, context, signal, fencingToken);
  }

  // ì‹¤ì œ LLM ì„œë²„ í˜¸ì¶œ
  return callLLMServer(job, jobId, query, context, signal, fencingToken);
}

/**
 * ì‹¤ì œ LLM ì„œë²„ í˜¸ì¶œ (SSE ìŠ¤íŠ¸ë¦¼)
 */
async function callLLMServer(
  job: Job,
  jobId: string,
  query: string,
  context: JobContext,
  signal: AbortSignal,
  fencingToken: string
): Promise<string> {
  console.log(`ğŸŒ [${workerId}] Calling LLM server: ${LLM_SERVER_URL}`);

  const response = await fetch(LLM_SERVER_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, jobId }),
    signal,  // abort() í˜¸ì¶œ ì‹œ ìš”ì²­ ì·¨ì†Œë¨
  });

  if (!response.ok) {
    throw new Error(`LLM server error: ${response.status}`);
  }

  const reader = response.body?.getReader();
  if (!reader) {
    throw new Error('No response body');
  }

  const decoder = new TextDecoder();
  let summary = '';

  try {
    while (true) {
      // abort ì²´í¬
      if (signal.aborted || context.isAborted) {
        throw new UnrecoverableError('Job was aborted');
      }

      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      const lines = chunk.split('\n').filter(line => line.startsWith('data: '));

      for (const line of lines) {
        const data = JSON.parse(line.slice(6));

        console.log(`ğŸ“ [${workerId}] LLM progress: ${data.percent}%`);

        // ì§„í–‰ ìƒí™© ë°œí–‰
        if (!context.isAborted) {
          await publish(jobId, fencingToken, {
            status: 'progress',
            workerId,
            percent: data.percent,
            message: data.message,
            timestamp: new Date().toISOString(),
          });
        }

        // BullMQ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        await job.updateProgress(data.percent);

        if (data.summary) {
          summary = data.summary;
        }
      }
    }
  } finally {
    reader.releaseLock();
  }

  return summary || `Research completed for: ${jobId}`;
}

/**
 * ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (LLM ì„œë²„ ì—†ì„ ë•Œ)
 */
async function executeResearchSimulation(
  job: Job,
  jobId: string,
  context: JobContext,
  signal: AbortSignal,
  fencingToken: string
): Promise<string> {
  console.log(`ğŸ”¬ [${workerId}] Simulation mode (no LLM_SERVER_URL)`);

  const steps = [
    { percent: 10, message: 'ë¬¸ì„œ ìˆ˜ì§‘ ì¤‘...' },
    { percent: 25, message: '1ì°¨ ë¶„ì„ ì¤‘...' },
    { percent: 50, message: 'ì‹¬ì¸µ ë¶„ì„ ì¤‘...' },
    { percent: 75, message: 'ê²°ê³¼ ì¢…í•© ì¤‘...' },
    { percent: 90, message: 'ë³´ê³ ì„œ ì‘ì„± ì¤‘...' },
    { percent: 100, message: 'ì™„ë£Œ' },
  ];

  for (const step of steps) {
    // Abort ì²´í¬
    if (signal.aborted || context.isAborted) {
      throw new UnrecoverableError('Job was aborted');
    }

    console.log(`ğŸ“ [${workerId}] Progress: ${step.percent}% - ${step.message}`);

    // ì§„í–‰ ìƒí™© ë°œí–‰
    if (!context.isAborted) {
      await publish(jobId, fencingToken, {
        status: 'progress',
        workerId,
        percent: step.percent,
        message: step.message,
        timestamp: new Date().toISOString(),
      });
    }

    // BullMQ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    await job.updateProgress(step.percent);

    // ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ (2ì´ˆ ëŒ€ê¸°, abort ê°€ëŠ¥)
    await interruptibleDelay(2000, signal);
  }

  return `Research completed for: ${jobId}`;
}

const worker = new Worker(
  'deep-research',
  async (job: Job) => {
    const { query, jobId } = job.data;

    // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ jobì¸ì§€ í™•ì¸
    if (activeJobs.has(jobId)) {
      console.log(`âš ï¸ [${workerId}] Job already running: ${jobId}`);
      throw new UnrecoverableError('Job already running in this worker');
    }

    // AbortController ìƒì„±
    const abortController = new AbortController();
    const { signal } = abortController;

    // íœì‹± í† í° íšë“
    const fencingToken = await acquireFencingToken(jobId);

    // Job ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    const context: JobContext = {
      abortController,
      fencingToken,
      lockExtendInterval: null,
      isAborted: false,
    };

    activeJobs.set(jobId, context);

    console.log(`\n${'='.repeat(60)}`);
    console.log(`ğŸš€ [${workerId}] STALLED WORKER picked up job: ${jobId}`);
    console.log(`â° Attempt: ${job.attemptsMade + 1}`);
    console.log(`ğŸ” Fencing Token: ${fencingToken.substring(0, 8)}...`);
    console.log(`${'='.repeat(60)}\n`);

    try {
      // Lock ìë™ ê°±ì‹  + í† í° ê²€ì¦ ì‹œì‘ (10ì´ˆë§ˆë‹¤)
      context.lockExtendInterval = startLockExtension(job, jobId, signal, context);

      // ì‹œì‘ ì•Œë¦¼
      await publish(jobId, fencingToken, {
        status: 'started',
        workerId,
        attempt: job.attemptsMade + 1,
        message: 'STALLED WORKER TOOK OVER',
        timestamp: new Date().toISOString(),
      });

      // LLM ì„œë²„ í˜¸ì¶œ ë˜ëŠ” ì‹œë®¬ë ˆì´ì…˜
      const summary = await executeResearch(job, jobId, query, context, signal, fencingToken);

      await publish(jobId, fencingToken, {
        status: 'completed',
        workerId,
        query,
        summary,
        timestamp: new Date().toISOString(),
      });
      await releaseFencingToken(jobId, fencingToken);

      console.log(`\nâœ… [${workerId}] Job completed: ${jobId}\n`);

      return { summary };
    } catch (error) {
      if (signal.aborted || context.isAborted) {
        console.log(`ğŸ›‘ [${workerId}] Job aborted: ${jobId}`);
        throw new UnrecoverableError('Job was aborted - zombie process terminated');
      }

      console.error(`âŒ [${workerId}] Job failed: ${jobId}`, error);

      await publish(jobId, fencingToken, {
        status: 'error',
        workerId,
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString(),
      });

      throw error;
    } finally {
      cleanupJob(jobId);
    }
  },
  {
    connection: { host: 'localhost', port: 6379 },
    lockDuration: 30000,      // 30ì´ˆ
    stalledInterval: 15000,   // 15ì´ˆë§ˆë‹¤ ì²´í¬
    maxStalledCount: 1,       // 1ë²ˆë§Œ stalled í—ˆìš©
    concurrency: 1,
  }
);

console.log('ğŸ¯ Stalled worker listening...\n');

// Graceful shutdown
process.on('SIGINT', async () => {
  console.log('\nğŸ›‘ Shutting down stalled worker...');

  // ëª¨ë“  í™œì„± job ì¤‘ë‹¨
  for (const [jobId] of activeJobs) {
    abortJob(jobId, 'Worker shutdown');
  }

  await worker.close();
  await redis.quit();
  process.exit(0);
});
