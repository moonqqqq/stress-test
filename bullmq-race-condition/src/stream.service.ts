import { Injectable, OnModuleInit, OnModuleDestroy } from '@nestjs/common';
import Redis from 'ioredis';

interface StreamData {
  status: string;
  workerId: string;
  fencingToken?: string;
  [key: string]: any;
}

interface FencingTokenInfo {
  token: string;
  workerId: string;
  createdAt: number;
}

@Injectable()
export class StreamService implements OnModuleInit, OnModuleDestroy {
  private publisher: Redis;
  private subscriber: Redis;
  private subscriptions = new Map<string, ((data: StreamData) => void)[]>();

  // íœì‹± í† í° TTL (ì´ˆ) - jobì´ ì™„ë£Œë˜ê±°ë‚˜ ì·¨ì†Œë  ë•Œê¹Œì§€ ìœ íš¨
  private readonly FENCING_TOKEN_TTL = 3600; // 1ì‹œê°„

  async onModuleInit() {
    this.publisher = new Redis({ host: 'localhost', port: 6379 });
    this.subscriber = new Redis({ host: 'localhost', port: 6379 });

    console.log('ğŸ“¡ Stream service initialized with fencing token support');

    this.startListening();
  }

  async onModuleDestroy() {
    await this.publisher.quit();
    await this.subscriber.quit();
  }

  /**
   * íœì‹± í† í° ë°œê¸‰
   *
   * ìƒˆë¡œìš´ job ì²˜ë¦¬ê°€ ì‹œì‘ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
   * ì´ì „ í† í°ì„ ë¬´íš¨í™”í•˜ê³  ìƒˆ í† í°ì„ ë°œê¸‰í•©ë‹ˆë‹¤.
   */
  async acquireFencingToken(jobId: string, workerId: string): Promise<string> {
    const tokenKey = `fencing:${jobId}`;
    const token = `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;

    const tokenInfo: FencingTokenInfo = {
      token,
      workerId,
      createdAt: Date.now(),
    };

    // ì›ìì ìœ¼ë¡œ ìƒˆ í† í° ì„¤ì • (ì´ì „ í† í° ìë™ ë¬´íš¨í™”)
    await this.publisher.set(
      tokenKey,
      JSON.stringify(tokenInfo),
      'EX',
      this.FENCING_TOKEN_TTL
    );

    console.log(`ğŸ” [${workerId}] Acquired fencing token: ${token.substring(0, 8)}...`);

    return token;
  }

  /**
   * íœì‹± í† í° ê²€ì¦
   *
   * ìŠ¤íŠ¸ë¦¼ì— ì“°ê¸° ì „ì— í˜„ì¬ í† í°ì´ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
   */
  async validateFencingToken(jobId: string, token: string): Promise<boolean> {
    const tokenKey = `fencing:${jobId}`;
    const storedData = await this.publisher.get(tokenKey);

    if (!storedData) {
      return false;
    }

    const tokenInfo: FencingTokenInfo = JSON.parse(storedData);
    return tokenInfo.token === token;
  }

  /**
   * íœì‹± í† í° í•´ì œ (job ì™„ë£Œ ì‹œ)
   */
  async releaseFencingToken(jobId: string, token: string): Promise<void> {
    const tokenKey = `fencing:${jobId}`;

    // í† í°ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ì—ë§Œ ì‚­ì œ (Lua scriptë¡œ ì›ìì  ì²˜ë¦¬)
    const script = `
      local stored = redis.call('GET', KEYS[1])
      if stored then
        local info = cjson.decode(stored)
        if info.token == ARGV[1] then
          redis.call('DEL', KEYS[1])
          return 1
        end
      end
      return 0
    `;

    await this.publisher.eval(script, 1, tokenKey, token);
  }

  /**
   * Redis Streamì— ë°ì´í„° ë°œí–‰ (ê²€ì¦ ì—†ì´)
   *
   * íœì‹± í† í° ê²€ì¦ì€ Lock ê°±ì‹  ì‹œì ì— ë³„ë„ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
   * ì´ ë°©ì‹ìœ¼ë¡œ Redis í˜¸ì¶œ ë¹ˆë„ë¥¼ ì¤„ì…ë‹ˆë‹¤.
   */
  async publish(jobId: string, data: StreamData, fencingToken?: string): Promise<void> {
    const streamKey = `research:${jobId}`;

    // í† í° ì •ë³´ë¥¼ ë°ì´í„°ì— í¬í•¨ (ë‚˜ì¤‘ì— í•„í„°ë§ìš©)
    const enrichedData = {
      ...data,
      fencingToken: fencingToken ? fencingToken.substring(0, 8) : 'none',
    };

    console.log(
      `ğŸ“¤ [${data.workerId}] Publishing to ${streamKey}:`,
      JSON.stringify({ status: data.status, step: data.step || 'N/A' })
    );

    // ê²€ì¦ ì—†ì´ ë°”ë¡œ ë°œí–‰ (XADD + PUBLISH)
    await this.publisher.xadd(streamKey, '*', 'data', JSON.stringify(enrichedData));
    await this.publisher.publish(streamKey, JSON.stringify(enrichedData));
  }

  /**
   * íŠ¹ì • jobì˜ ìŠ¤íŠ¸ë¦¼ êµ¬ë…
   */
  subscribe(jobId: string, callback: (data: StreamData) => void) {
    const streamKey = `research:${jobId}`;

    if (!this.subscriptions.has(streamKey)) {
      this.subscriptions.set(streamKey, []);
      this.subscriber.subscribe(streamKey);
    }

    this.subscriptions.get(streamKey)!.push(callback);
  }

  /**
   * ìŠ¤íŠ¸ë¦¼ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (íœì‹± í† í° ì •ë³´ í¬í•¨)
   */
  async getHistory(jobId: string): Promise<any[]> {
    const streamKey = `research:${jobId}`;

    const entries = await this.publisher.xrange(streamKey, '-', '+');

    return entries.map(([id, fields]) => ({
      streamId: id,
      ...JSON.parse(fields[1]),
    }));
  }

  /**
   * ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§í•œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
   */
  async getValidHistory(jobId: string): Promise<any[]> {
    const history = await this.getHistory(jobId);

    // ê°€ì¥ ìµœê·¼ íœì‹± í† í°ì„ ê°€ì§„ ë°ì´í„°ë§Œ ë°˜í™˜
    const tokenGroups = new Map<string, any[]>();

    for (const entry of history) {
      const token = entry.fencingToken || 'none';
      if (!tokenGroups.has(token)) {
        tokenGroups.set(token, []);
      }
      tokenGroups.get(token)!.push(entry);
    }

    // completed ìƒíƒœë¥¼ ê°€ì§„ ê·¸ë£¹ ì°¾ê¸°
    for (const [, entries] of tokenGroups) {
      if (entries.some(e => e.status === 'completed')) {
        return entries;
      }
    }

    // ì—†ìœ¼ë©´ ê°€ì¥ ìµœê·¼ í† í° ê·¸ë£¹ ë°˜í™˜
    const tokens = Array.from(tokenGroups.keys()).sort().reverse();
    return tokens.length > 0 ? tokenGroups.get(tokens[0])! : [];
  }

  private startListening() {
    this.subscriber.on('message', (channel, message) => {
      const callbacks = this.subscriptions.get(channel);
      if (callbacks) {
        const data = JSON.parse(message);
        callbacks.forEach((cb) => cb(data));
      }
    });
  }
}
